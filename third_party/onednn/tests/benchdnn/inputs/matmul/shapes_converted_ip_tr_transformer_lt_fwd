# These problems are ported from corresponding inner product shapes for
# training forward

# encoder
5120x1024:1024x1024n"transformer_lt_train:FWD,encoder:SA*2"
5120x1024:1024x4096n"transformer_lt_train:FWD,encoder:FF1*1"
5120x4096:4096x1024n"transformer_lt_train:FWD,encoder:FF2*1"
20480x1024:1024x1024n"transformer_lt_train:FWD,encoder:SA-precompute*1"
# decoder
512x1024:1024x1024n"transformer_lt_train:FWD,decoder:SA1*1"
# mb5120ic1024oc1024n"transformer_lt:decoder:SA10"
10240x1024:1024x1024n"transformer_lt_train:FWD,decoder:SA20*1"
512x1024:1024x4096n"transformer_lt_train:FWD,decoder:FF1*1"
512x4096:4096x1024n"transformer_lt_train:FWD,decoder:FF2*1"
# vocabulary
512x10246:10246x33945n"transformer_lt_train:FWD,output_logits*1"
